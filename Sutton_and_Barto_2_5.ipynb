{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sutton and Barto 2.5",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4v5WvTBlq6R5Z4mdOspJV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylerwilliams1010/Reinforcement_Learning/blob/master/Sutton_and_Barto_2_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRtx2mHpE3mN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import operator\n",
        "\n",
        "#Sutton and Barto 2.5\n",
        "'''Design and conduct an experiment to demonstrate the\n",
        "diculties that sample-average methods have for nonstationary problems. Use a modified\n",
        "version of the 10-armed testbed in which all the q⇤(a) start out equal and then take\n",
        "independent random walks (say by adding a normally distributed increment with mean\n",
        "zero and standard deviation 0.01 to all the q⇤(a) on each step). Prepare plots like\n",
        "Figure 2.2 for an action-value method using sample averages, incrementally computed,\n",
        "and another action-value method using a constant step-size parameter, alpha = 0.1. Use\n",
        "epsilon = 0.1 and longer runs, say of 10,000 steps.'''\n",
        "\n",
        "#Initial Values set to 0\n",
        "\n",
        "start_val = 0\n",
        "q_dict = {0:start_val,1:start_val,2:start_val,3:start_val,4:start_val,5:start_val,6:start_val,7:start_val,8:start_val,9:start_val}\n",
        "\n",
        "v_start_val = 1\n",
        "v_dict = {0:v_start_val,1:v_start_val,2:v_start_val,3:v_start_val,4:v_start_val,5:v_start_val,6:v_start_val,7:v_start_val,8:v_start_val,9:v_start_val}\n",
        "#Initialize variables\n",
        "eps = 0.1\n",
        "alpha = 0.1\n",
        "steps = 10000\n",
        "mu = 0\n",
        "stdev = 0.01\n",
        "\n",
        "def modify_values():\n",
        "  for val in v_dict:\n",
        "    v_dict[val] = v_dict[val] + random.gauss(mu, stdev)\n",
        "\n",
        "def agent_action():\n",
        "\n",
        "  # Choose which k to do\n",
        "  num = random.randint(1,100)\n",
        "  if num > (eps * 100):\n",
        "    k_action = max(q_dict.items(), key=operator.itemgetter(1))[0]\n",
        "  else:\n",
        "    k_action = random.randint(0,9)\n",
        "\n",
        "  # Take Action\n",
        "  reward = v_dict[k_action]\n",
        "  return reward, k_action\n",
        "\n",
        "def update_q_dict(reward, k_action):\n",
        "  q_dict[k_action] = q_dict[k_action] + alpha * (reward - q_dict[k_action])\n",
        "\n",
        "\n",
        "def ten_armed_bandit_problem():\n",
        "  for step in range(steps):\n",
        "    modify_values()\n",
        "    reward, k_action = agent_action()\n",
        "    update_q_dict(reward,k_action)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AYEjj8EFO3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ten_armed_bandit_problem()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tAJEw5HGxZj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "e9189a67-23b9-4333-9381-8df922f3e6c0"
      },
      "source": [
        "v_dict"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 4.001133981340513,\n",
              " 1: -14.421370519314737,\n",
              " 2: 2.8264929121014006,\n",
              " 3: 8.54896911428101,\n",
              " 4: 14.015530892119136,\n",
              " 5: 13.643306474449139,\n",
              " 6: -7.346450409821102,\n",
              " 7: 9.74813592961407,\n",
              " 8: 1.3753810288124706,\n",
              " 9: 7.562452805304729}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwgLKGF2Gyyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "9fc90a19-17a3-44ff-e461-bf51c064d20d"
      },
      "source": [
        "q_dict"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 3.752762662578036,\n",
              " 1: -14.639062537927524,\n",
              " 2: 2.6579937973444987,\n",
              " 3: 8.277372340511475,\n",
              " 4: 14.03184966238541,\n",
              " 5: 13.23960252501438,\n",
              " 6: -6.849405078063711,\n",
              " 7: 9.34262010819756,\n",
              " 8: 1.5170787104149643,\n",
              " 9: 7.415154704844481}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRUk0I4dKLhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}